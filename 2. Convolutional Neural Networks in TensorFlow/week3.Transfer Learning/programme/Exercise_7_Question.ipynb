{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b532a551-5082-4c38-c373-520260df5b04"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.python.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-25 22:09:51--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.128, 2607:f8b0:4001:c1b::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   118MB/s    in 0.7s    \n",
            "\n",
            "2020-01-25 22:09:51 (118 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb536d4f-e6b5-47d7-9d17-6f7edf9fbc18"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4cbee01-4d32-481a-927a-835420edee44"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "5a4aa0b9-51bd-4f63-b279-f12c83e6417f"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-25 22:13:28--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.128, 2607:f8b0:4001:c16::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   233MB/s    in 0.6s    \n",
            "\n",
            "2020-01-25 22:13:29 (233 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-01-25 22:13:30--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c18::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-01-25 22:13:30 (82.5 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3dad83d4-7e9e-47f8-8083-f1cc4a9e2367"
      },
      "source": [
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8d196574-bc34-4deb-f5ab-e65c3d6cd8a0"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb4ec913-7308-4fc3-8ede-11e3ff85d97b"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "100/100 - 33s - loss: 0.1721 - acc: 0.9296 - val_loss: 0.0105 - val_acc: 0.9919\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0744 - acc: 0.9747 - val_loss: 0.0103 - val_acc: 0.9960\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0614 - acc: 0.9782 - val_loss: 0.1268 - val_acc: 0.9656\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0311 - acc: 0.9904 - val_loss: 0.0351 - val_acc: 0.9919\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0496 - acc: 0.9843 - val_loss: 0.0393 - val_acc: 0.9929\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0477 - acc: 0.9843 - val_loss: 0.0474 - val_acc: 0.9960\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0373 - acc: 0.9883 - val_loss: 0.2605 - val_acc: 0.9565\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0246 - acc: 0.9914 - val_loss: 0.0359 - val_acc: 0.9919\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0206 - acc: 0.9914 - val_loss: 0.0758 - val_acc: 0.9879\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0332 - acc: 0.9929 - val_loss: 0.0980 - val_acc: 0.9879\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0186 - acc: 0.9924 - val_loss: 0.0989 - val_acc: 0.9879\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0401 - acc: 0.9899 - val_loss: 0.2065 - val_acc: 0.9717\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0145 - acc: 0.9954 - val_loss: 0.2186 - val_acc: 0.9676\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.3106 - val_acc: 0.9595\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0158 - acc: 0.9949 - val_loss: 0.1816 - val_acc: 0.9686\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0200 - acc: 0.9944 - val_loss: 0.4803 - val_acc: 0.9534\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0333 - acc: 0.9914 - val_loss: 0.4354 - val_acc: 0.9565\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0223 - acc: 0.9934 - val_loss: 1.1195 - val_acc: 0.9393\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0374 - acc: 0.9909 - val_loss: 0.1742 - val_acc: 0.9787\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0144 - acc: 0.9949 - val_loss: 0.2559 - val_acc: 0.9727\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0101 - acc: 0.9965 - val_loss: 0.5950 - val_acc: 0.9494\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0061 - acc: 0.9980 - val_loss: 0.3757 - val_acc: 0.9585\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0243 - acc: 0.9934 - val_loss: 0.7535 - val_acc: 0.9494\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0123 - acc: 0.9944 - val_loss: 1.3249 - val_acc: 0.9372\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0236 - acc: 0.9954 - val_loss: 0.8767 - val_acc: 0.9494\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0249 - acc: 0.9940 - val_loss: 1.0937 - val_acc: 0.9423\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0145 - acc: 0.9959 - val_loss: 1.7867 - val_acc: 0.9231\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0105 - acc: 0.9959 - val_loss: 0.7836 - val_acc: 0.9504\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0167 - acc: 0.9965 - val_loss: 0.9534 - val_acc: 0.9443\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0138 - acc: 0.9944 - val_loss: 0.4498 - val_acc: 0.9615\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0164 - acc: 0.9949 - val_loss: 1.4922 - val_acc: 0.9322\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0073 - acc: 0.9985 - val_loss: 0.4545 - val_acc: 0.9605\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0283 - acc: 0.9945 - val_loss: 0.9489 - val_acc: 0.9504\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0052 - acc: 0.9990 - val_loss: 1.2276 - val_acc: 0.9474\n",
            "Epoch 35/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0161 - acc: 0.9959 - val_loss: 1.5164 - val_acc: 0.9372\n",
            "Epoch 36/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0056 - acc: 0.9975 - val_loss: 0.4493 - val_acc: 0.9686\n",
            "Epoch 37/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0213 - acc: 0.9944 - val_loss: 0.7843 - val_acc: 0.9555\n",
            "Epoch 38/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0147 - acc: 0.9955 - val_loss: 1.1331 - val_acc: 0.9433\n",
            "Epoch 39/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0100 - acc: 0.9949 - val_loss: 0.3475 - val_acc: 0.9686\n",
            "Epoch 40/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0195 - acc: 0.9954 - val_loss: 0.4416 - val_acc: 0.9615\n",
            "Epoch 41/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0215 - acc: 0.9949 - val_loss: 0.4129 - val_acc: 0.9656\n",
            "Epoch 42/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0139 - acc: 0.9965 - val_loss: 0.9417 - val_acc: 0.9474\n",
            "Epoch 43/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0085 - acc: 0.9975 - val_loss: 1.2289 - val_acc: 0.9413\n",
            "Epoch 44/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0030 - acc: 0.9985 - val_loss: 0.8320 - val_acc: 0.9534\n",
            "Epoch 45/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0165 - acc: 0.9959 - val_loss: 0.7667 - val_acc: 0.9555\n",
            "Epoch 46/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0190 - acc: 0.9965 - val_loss: 0.6385 - val_acc: 0.9595\n",
            "Epoch 47/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0083 - acc: 0.9975 - val_loss: 0.4664 - val_acc: 0.9757\n",
            "Epoch 48/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0085 - acc: 0.9969 - val_loss: 0.6234 - val_acc: 0.9524\n",
            "Epoch 49/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0161 - acc: 0.9960 - val_loss: 0.9200 - val_acc: 0.9443\n",
            "Epoch 50/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.4503 - val_acc: 0.9696\n",
            "Epoch 51/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0054 - acc: 0.9985 - val_loss: 0.7797 - val_acc: 0.9545\n",
            "Epoch 52/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0088 - acc: 0.9985 - val_loss: 1.1420 - val_acc: 0.9413\n",
            "Epoch 53/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0241 - acc: 0.9949 - val_loss: 0.9842 - val_acc: 0.9464\n",
            "Epoch 54/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0193 - acc: 0.9949 - val_loss: 1.4207 - val_acc: 0.9453\n",
            "Epoch 55/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0152 - acc: 0.9954 - val_loss: 0.9607 - val_acc: 0.9474\n",
            "Epoch 56/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0228 - acc: 0.9965 - val_loss: 1.3375 - val_acc: 0.9403\n",
            "Epoch 57/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0148 - acc: 0.9975 - val_loss: 1.4615 - val_acc: 0.9362\n",
            "Epoch 58/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0212 - acc: 0.9959 - val_loss: 1.8089 - val_acc: 0.9362\n",
            "Epoch 59/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0160 - acc: 0.9975 - val_loss: 1.0684 - val_acc: 0.9423\n",
            "Epoch 60/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0077 - acc: 0.9980 - val_loss: 2.1507 - val_acc: 0.9291\n",
            "Epoch 61/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0244 - acc: 0.9955 - val_loss: 1.2993 - val_acc: 0.9403\n",
            "Epoch 62/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0080 - acc: 0.9980 - val_loss: 1.4775 - val_acc: 0.9393\n",
            "Epoch 63/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0138 - acc: 0.9975 - val_loss: 1.0262 - val_acc: 0.9433\n",
            "Epoch 64/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0139 - acc: 0.9949 - val_loss: 1.0341 - val_acc: 0.9474\n",
            "Epoch 65/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0122 - acc: 0.9975 - val_loss: 0.8493 - val_acc: 0.9524\n",
            "Epoch 66/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0328 - acc: 0.9975 - val_loss: 1.1317 - val_acc: 0.9443\n",
            "Epoch 67/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0079 - acc: 0.9985 - val_loss: 0.7626 - val_acc: 0.9585\n",
            "Epoch 68/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 24s - loss: 0.0021 - acc: 0.9995 - val_loss: 1.1711 - val_acc: 0.9453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "af71acc8-17ae-4576-ad25-e9deefa5d7b4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD8SCv2EYRg/Egr9hGEYP5P8BrkMySFatV04AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GepKS7vg4z3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}